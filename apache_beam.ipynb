{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Beam \n",
    "\n",
    "* With beam we can process data for streaming or batch\n",
    "* We can choose our runner, like spark or dataflow\n",
    "* Beam works in parallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the results\n",
    "\n",
    "to show the elements we can use .LogElements() or .Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install apache-beam\n",
    "#!pip install apache-beam[interactive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Beam\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create(['Hello Beam'])\n",
    "     | beam.LogElements())\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam\n",
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  hello_beam = (p \n",
    "     | beam.Create(['Hello Beam']))\n",
    "  \n",
    "  hello = (hello_beam\n",
    "    | beam.Map(lambda x: x.split()[0])\n",
    "    | \"Print Hello\" >> beam.Map(print))\n",
    "    \n",
    "  beam = (hello_beam \n",
    "    | beam.Map(lambda x: x.split()[1])\n",
    "    | \"Print Beam\" >> beam.Map(print))  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combiners"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can combine values in apache beam i a lot of ways\n",
    "\n",
    "* Simple Aggregation\n",
    "* byKey\n",
    "* byElements\n",
    "\n",
    "In this example we will use the Count method in the three ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many itens has in my array\n",
      "5\n",
      "\n",
      "Calculating repetead keys\n",
      "('laranja', 2)\n",
      "('maça', 2)\n",
      "('banana', 1)\n",
      "\n",
      "Calculatind repetead elements\n",
      "(('laranja', 1), 2)\n",
      "(('maça', 1), 1)\n",
      "(('maça', 2), 1)\n",
      "(('banana', 4), 1)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "my_array_of_fruits = [\n",
    "    (\"laranja\", 1),\n",
    "    (\"maça\", 1),\n",
    "    (\"laranja\", 1),\n",
    "    (\"maça\", 2),\n",
    "    (\"banana\", 4)\n",
    "  ]\n",
    "\n",
    "print(\"How many itens has in my array\")\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  numbers = (p | beam.Create(my_array_of_fruits))\n",
    "\n",
    "  count = (numbers \n",
    "         | beam.combiners.Count.Globally()\n",
    "         | \"count\" >> beam.LogElements())\n",
    "  \n",
    "print(\"\\nCalculating repetead keys\")\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "  numbers = (p | beam.Create(my_array_of_fruits))\n",
    "\n",
    "  count_by_key = (numbers \n",
    "           | beam.combiners.Count().PerKey()\n",
    "           | beam.LogElements())\n",
    "  \n",
    "print(\"\\nCalculating repetead elements\")\n",
    "with beam.Pipeline() as p:\n",
    "  numbers = (p | beam.Create(my_array_of_fruits))\n",
    "  \n",
    "  count_by_elements = ((numbers \n",
    "           | beam.combiners.Count().PerElement()\n",
    "           | beam.LogElements()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can use .CombinePerKey() and choose our function like .CombinePerKey(sum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some built-in methos in Beam\n",
    "\n",
    "* .Top\n",
    "* .Mean\n",
    "* .ToSet\n",
    "* .ToDict\n",
    "* .Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "5.5\n",
      "[1, 2, 3]\n",
      "[10, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "# Also we have .perKey() in Top\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  numbers = (p | beam.Create(range(1, 11)))\n",
    "  \n",
    "  smallest = (numbers\n",
    "     | beam.combiners.Top.Smallest(3)\n",
    "     | \"smallest\" >> beam.LogElements())\n",
    "  \n",
    "  largest = (numbers\n",
    "     | beam.combiners.Top.Largest(3)\n",
    "     | \"largest\" >> beam.LogElements())\n",
    "  \n",
    "  average = (numbers\n",
    "     | beam.combiners.Mean().Globally()\n",
    "     | \"average\" >> beam.LogElements())\n",
    "\n",
    "  transform_in_set = (numbers\n",
    "      | beam.combiners.ToSet()\n",
    "      | \"transform in set\" >> beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For complex combining we can create our own functions\n",
    "* .CombineFn\n",
    "\n",
    "* SimpleFunctions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'odd_count': 2, 'even_count': 3}\n"
     ]
    }
   ],
   "source": [
    "class OddEvenCounter(beam.CombineFn):\n",
    "    def create_accumulator(self):\n",
    "        return {'odd_count': 0, 'even_count': 0}           # This is a space to store our values\n",
    "    \n",
    "    def add_input(self, accumulator, element):\n",
    "        if element % 2 == 0:\n",
    "            accumulator['even_count'] += 1              # Here we are adding value in our space\n",
    "        else:\n",
    "            accumulator['odd_count'] += 1\n",
    "        return accumulator\n",
    "            \n",
    "    def merge_accumulators(self, accumulators):\n",
    "        result = {'odd_count': 0, 'even_count': 0}\n",
    "        for accumulator in accumulators:                    # Now we are grouping all our spaces and aggregating them\n",
    "            result['odd_count'] += accumulator['odd_count']\n",
    "            result['even_count'] += accumulator['even_count']\n",
    "        return result\n",
    "    \n",
    "    def extract_output(self, accumulator):               # here we return our output\n",
    "        return accumulator\n",
    "\n",
    "    \n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([10, 3, 5, 70, 90])\n",
    "     | beam.CombineGlobally(OddEvenCounter())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945000\n"
     ]
    }
   ],
   "source": [
    "def multiply(numbers):\n",
    "  total = 1\n",
    "\n",
    "  for num in numbers:\n",
    "      total *= num\n",
    "\n",
    "  return total\n",
    "    \n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([10, 3, 5, 70, 90])\n",
    "     | beam.CombineGlobally(multiply)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping And Filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bahia', 'BA']\n",
      "['São', 'Paulo', 'SP']\n",
      "['Rio', 'De', 'Janeiro', 'RJ']\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "     | beam.Map(lambda x: x.split())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".flatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bahia\n",
      "BA\n",
      "São\n",
      "Paulo\n",
      "SP\n",
      "Rio\n",
      "De\n",
      "Janeiro\n",
      "RJ\n"
     ]
    }
   ],
   "source": [
    "# Do an action in \n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "     | beam.FlatMap(lambda x: x.split())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bahia BA\n"
     ]
    }
   ],
   "source": [
    "# Filtering only states from Nordeste in Brazil\n",
    "class Nordeste(beam.DoFn):\n",
    "    def process(self, element, lower_case):\n",
    "        siglas_nordeste = ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']\n",
    "\n",
    "        if element.split()[1] in siglas_nordeste:\n",
    "            if lower_case==True:\n",
    "                yield element.lower()\n",
    "            else:\n",
    "                yield element\n",
    "\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "     | beam.ParDo(Nordeste(), lower_case=False) # we can pass other arguments to the ParDo function\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bahia BA\n"
     ]
    }
   ],
   "source": [
    "siglas_nordeste = ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']\n",
    "\n",
    "# Filtering only states from Nordeste in Brazil\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "     | beam.Filter(lambda x: x.split()[1] in siglas_nordeste)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".WithKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BA', 'Bahia BA')\n",
      "('SP', 'São Paulo SP')\n",
      "('RJ', 'Rio De Janeiro RJ')\n"
     ]
    }
   ],
   "source": [
    "# Select the keys of the elements\n",
    "with beam.Pipeline() as p:\n",
    "    (p | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "     | beam.WithKeys(lambda x: x.split()[-1])\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and Partition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slicing with tags\n",
    "\n",
    "ideal for parallel operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Nordeste > Bahia BA\n",
      "From Sudeste > São Paulo SP\n",
      "From Sudeste > Rio De Janeiro RJ\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "\n",
    "# Filtering only states from Nordeste in Brazil\n",
    "class Nordeste(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        siglas_nordeste = ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']\n",
    "\n",
    "        if element.split()[1] in siglas_nordeste:\n",
    "            yield element\n",
    "        else:\n",
    "            yield pvalue.TaggedOutput('Sudeste', element) # Atribute a Tag for the else elements\n",
    "\n",
    "# Creating Tags to our states based in out DoFn filter\n",
    "with beam.Pipeline() as p:\n",
    "    results = (p \n",
    "               | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "               | beam.ParDo(Nordeste()).with_outputs('Sudeste', main='Nordeste'))\n",
    "\n",
    "    results['Nordeste'] | 'Nordeste' >> beam.LogElements(prefix='From Nordeste > ')\n",
    "    results['Sudeste'] | 'Sudeste' >> beam.LogElements(prefix='From Sudeste > ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".partition\n",
    "\n",
    "(ideal to no parallel operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Nordeste > Bahia BA\n",
      "From Sudeste > São Paulo SP\n",
      "From Sudeste > Rio De Janeiro RJ\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "\n",
    "# Filtering only states from Nordeste in Brazil\n",
    "def partitionFn(element, num_partitions):\n",
    "    siglas_nordeste = ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']\n",
    "\n",
    "    if element.split()[1] in siglas_nordeste:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 # Atribute a Tag for the else elements\n",
    "\n",
    "# Creating Tags to our states based in out DoFn filter\n",
    "with beam.Pipeline() as p:\n",
    "    results = (p \n",
    "               | beam.Create(['Bahia BA', 'São Paulo SP', 'Rio De Janeiro RJ'])\n",
    "               | beam.Partition(partitionFn, 2)\n",
    "    )\n",
    "\n",
    "    results[0] | 'Nordeste' >> beam.LogElements(prefix='From Nordeste > ')\n",
    "    results[1] | 'Sudeste' >> beam.LogElements(prefix='From Sudeste > ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    pip1 = (p | \"pip1\" >> beam.Create([1,2,3]))\n",
    "    pip2 = (p | \"pip2\" >> beam.Create([4,5,6]))\n",
    "\n",
    "    pip3 = ((pip1, pip2) \n",
    "            | beam.Flatten()\n",
    "            | beam.LogElements())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulate our Pipeline\n",
    "We can create a class with beam.PTransform, and create steps that repeat in ours pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "100\n",
      "75\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import apache_beam as beam\n",
    "from apache_beam import pvalue\n",
    "\n",
    "\n",
    "class Stats(beam.PTransform):\n",
    "\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "\n",
    "    class Sum(beam.DoFn):\n",
    "        def process(self, element):\n",
    "            return [element[0]+element[1]]\n",
    "    \n",
    "    class Multiply(beam.DoFn):\n",
    "        def process(self, element):\n",
    "            return [element[0]*element[1]]\n",
    "    \n",
    "    class Divide(beam.DoFn):\n",
    "        def process(self, element):\n",
    "            return [element[0]/element[1]]\n",
    "\n",
    "    class others_functions(beam.DoFn):\n",
    "        pass\n",
    "\n",
    "    def expand(self, pcoll):\n",
    "        if self.method == \"Mult\":\n",
    "            return (pcoll |\n",
    "                    beam.ParDo(Stats.Multiply())\n",
    "        )\n",
    "        else:\n",
    "            return(pcoll)\n",
    "\n",
    "# Creating Tags to our states based in out DoFn filter\n",
    "with beam.Pipeline() as p:\n",
    "    results = (p \n",
    "               | beam.Create([[7,6],[10,10],[15,5],[9,7]])\n",
    "               | Stats('Mult')\n",
    "               | beam.LogElements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
